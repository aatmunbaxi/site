#+hugo_base_dir: /home/aatmun/websites/personal/
#+hugo_weight: auto
#+bibliography: ~/Documents/bib/reference-texts.bib
#+bibliographystyle:
#+options: ':t todo:nil date:t
#+cite_export: csl
#+startup: logdone

* Home
:PROPERTIES:
:EXPORT_HUGO_SECTION:
:EXPORT_HUGO_FRONT_MATTER: :toc false :author false
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_WEIGHT: -10
:END:
** About Me
:PROPERTIES:
:EXPORT_HUGO_SECTION:
:EXPORT_HUGO_MENU: :menu main
:END:
I am a PhD student in mathematics at Texas A&M University. My advisor is Dr. [[https://www.math.tamu.edu/~rowell/][Eric Rowell]].

*Interests:* Fusion and modular categories and their classification. Some random things in algebraic geometry.

*** What I'm Reading
- /Tensor Categories/
*** Education
- PhD Mathematics, Texas A&M University (in progress)
- MS Mathematics, Texas A&M University 2023
- BS Mathematics, UCLA 2021
*** Conferences
- LAWRGe 2023 @ USC
*** Hobbies
- Programming and learning new programming languages. I'm currently working in the rust programming language.
- Liverpool FC
- Astrophotography. Check my images [[*Astrophotos][here]]
- Learning japanese through immersion
- Free (as in freedom) software
  - This site is deployed with the [[https://github.com/kaushalmodi/ox-hugo][ox-hugo]] program in GNU emacs

* Math
:PROPERTIES:
:EXPORT_HUGO_SECTION: math
:END:
** Math
:PROPERTIES:
:EXPORT_HUGO_SECTION: math
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_MENU: :menu main
:END:
Here I keep some thoughts about math-related things I find interesting or worth sharing.
** LAWRGe 2023 Notes :math:conference:notes:
:PROPERTIES:
:EXPORT_HUGO_SECTION: math
:EXPORT_FILE_NAME: LAWRGe_2023_notes
:END:
#+toc: headlines 2 local
#+include: "~/Documents/org/notes.org::*LAWRGe Workshop"
** DRAFT Quantum Computing, Braids, and Modular Categories :math:categories:
:PROPERTIES:
:EXPORT_HUGO_SECTION: math
:EXPORT_FILE_NAME: quantum_comp_and_modular_categories
:EXPORT_HUGO_FRONT_MATTER: :toc
:END:

*** Introduction
Quantum computing (QC) is an exciting new paradigm of computation, promising exponential speedup from state-of-the-art classical algorithms in certain computing tasks.
Despite vigorous research from all sides of the task, obstacles to a quantum computer architecture that is scalable and tolerant to errors inherent to the idiosyncrasies of the quantum world remain hard to overcome.

Qubits in existing models of quantum computation (such as trapped-ion models) are sensitive to their environment.
Such sensitivities of the environment make qubits liable to introducing noise that dominates the data we'd like to actually measure.
To ensure we can recover usable data, we'd (approximately) need on the order of thousands of physical qubits per logical qubit to near-guarantee our computation is correct.
This would be no issue if current QC implementations were highly scalable, but they are not.
Topological quantum computing is a theoretical basis to address both these issues simultaneously.

*** Anyons and their statistics
While traditional QC implementations use bosons and fermions for qubits, topological quantum computing (TQC) uses /anyons/.
Recall that two bosons exchange in a wave function causing a global phase shift \( +1 \) (i.e. \( | \varphi_1 \varphi_2 \rangle = | \varphi_2 \varphi_1 \rangle\)).
Conversely, fermions exchange with a global phase shift \( -1 \), so \( | \varphi_2 \varphi_2 \rangle = - | \varphi_2 \varphi_1 \rangle \).
Anyons are type of quasiparticle that allow for more general phase shifts \( e^{i\theta} \) for some real value of \( \theta \).
We recover boson and fermions at \( \theta= 0 \) and \( \theta=\pi \), respectively.
Anyons can take any statistics between Bose-Einstein statistics and Fermi-Dirac statistics and beyond, corresponding to values \( 0 \leqslant \theta \leqslant 2\pi \).

I've somewhat lied by omission in the previous paragraph.
The global phase shifts corresponding to \( e^{i\theta} \) are actually relevant to the so-called /abelian anyons/.
One can generalize this phase shift even further to an even larger class of unitary operators satisfying the [[https://en.wikipedia.org/wiki/Yang%E2%80%93Baxter_equation][Yang-Baxter equation]]; such quasiparticles are /non-abelian anyons/.
These non-abelian anyons are the building blocks to encoding information in TQC.
The question remains--/what does this buy us?/
I've already alluded to how TQC may be less sensitive to environmental noise than classical qubits, so we should understand how.

#+name: anyonexchange
#+caption: Inequivalent exchanges for identical anyons.
#+attr_html: :width 150%
[[file:figures/anyon_exchange.svg]]

When thinking about how anyons interact with each other, we must think topologically.
That is, we can do everything up to a "smooth/continuous" deformation.
In one dimension of space, nothing interesting can happen: we cannot exchange anyons at all.
In two dimensions of space, things get more interesting.
In a flatland with two particles, there are two topologically distinct paths a particle can take in the plane.
They are illustrated in Figure [[anyonexchange]].
#+name: braids
#+caption: Braids on \( n=3 \) strands traced out over time progression.
#+attr_html:  :width 150%
[[file:figures/braids.svg]]

At each slice of time, the position of anyons in flatland correspond to points in a plane.
Therefore, as we progress time, the trajectories of the anyons trace out paths akin to strands of string.
The strings cannot cross through each other, as this would mean the particles "collide" at some point in time.
Figure [[braids]] illustrates this phenomenon, with the arrow indicating the passage of time.

Mathematically, the collection of all these trajectories for some fixed \( n \) particles--so long as we disallow the strands reversing direction--form a group under composition: it is the *braid group on \( n \) strands*.
Here, the braid group is an instance of a more general kind of group called a *motion group*.
The mathematical formulation of this is to say that the braid group on \( n \) strands is the motion group of a disjoint union of points embedded in a compact box.
More general motion groups corresponding to excitation states of anyons exist, such as motions of circles or trefoils in a compact box; these are quite a bit more complicated, and we know little about them compared to the braid groups.

We can say that mathematically, the statistics of \( n \) anyons correspond to certain representations of the braid group on \( n \) strands.
From a practical perspective, the act of applying a quantum gate to a system of anyons would correspond to braiding them.
This basis for computing is intuitively less sensitive to environmental noise in the sense that the topological properties of braids are more stable under small perturbation.
One can imagine that it is easier for a ball to bump into a wall from a slight gust of wind than to rearrange two crossed strings so that the lower string lies on top without undoing the cross.
This comparison is not unlike the difference between the sensitivity of qubits in the classical QC world and the TQC world.
Study of braid groups, motion groups, and the unitary representations of these groups shed light on the behavior of anyons, making it a subject of physical interest, and not just one of intrinsic beauty.

*** Modular Categories
We switch gears a bit to discuss the other data of anyon systems, of which there are many.
The study of braids and their unitary representations will capture how anyons behave with respect to each other, but doesn't capture properties of the particles themselves.


[[bibliography:~/Documents/bib/zotero_refs.bib]]

*** Notes :noexport:
- quantum computing is not fault tolerant, based on physical limitations and introductions of noise in trapped quantum systems
- modular effectively model systems of anyon quasiparticles, the main ingredient to TQC (Kitaev)
- TQC allows for scalable fault-tolerant QC, where the error correction is performaed at the hardware level
  - This is perhaps its strongest merit
-  [[id:bf28ac60-b810-46e2-8716-5aae6737b51d][modularity corresponds to conservation laws of anyons]]
* Computing
:PROPERTIES:
:EXPORT_HUGO_SECTION: computing
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :type post
:END:
** Computing
:PROPERTIES:
:EXPORT_HUGO_SECTION: computing
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_MENU: :menu main
:END:
I've spent a lot of time developing a workflow that works well for me, mainly centered around my time typesetting math, and finding better ways to do so.
Here I record some things that I've learned along the way.

** Emacs =org-mode= for LaTeX :emacs:org:hobby:productivity:
:PROPERTIES:
:EXPORT_HUGO_SECTION: computing
:EXPORT_FILE_NAME: emacs-to-type-LaTeX
:END:
About four years ago, my brother introduced me to Linux and free and open source software.
Around the same time I learned to use LaTeX to typeset documents with lots of mathematical notation.
I then stumbled across Gilles Castel's [[https://castel.dev/post/lecture-notes-1/][article on typing LaTeX with vim]], and I was amazed.

For those who don't know, typing LaTeX by default is a terrible experience.
/Terrible./
Using a program like vim with plugins made typing LaTeX so frictionless that I immediately dove into the world of extensible text editors.
I got more than I bargained for, but the payoff of effortless typesetting of math drove me to stick with it.
I finally replicated most of Castel's setup, and thought I had seen it all.

Then I found emacs org-mode.

#+begin_export hugo
<style>
aside {
    width: 40%;
    padding-left: 0.5rem;
    margin-left: 0.5rem;
    float: right;
    box-shadow: inset 5px 0 5px -5px #29627e;
    font-style: italic;
    color: #7a7c7d;
}

aside > p {
    margin: 0.5rem;
}
</style>
#+end_export
#+begin_aside
#+begin_quote
GNU Emacs [is] a sort of hybrid between Windows Notepad, a monolithic-kernel operating system, and the International Space Station.

---Steve Yegge
#+end_quote
#+end_aside
Vim, the program I had been using for easy LaTeX input, has had a longstanding "rivalry" with another editor called GNU Emacs.
Since spending time with both programs, I've found this "rivalry" a bit silly.
Vim and emacs are different programs designed with different use cases in mind with different philosophies.
They just /happen/ to both be text editors.
Comparing vim and emacs is a bit like comparing a bicycle to a tank simply because they can move people around quicker than by foot.

In any case, what brought me to emacs was org-mode.
Org-mode is a major mode of emacs, encompassing everything from marking up basic text files and exporting to PDF, keeping an agenda, and literally everything else you could imagine needing when it comes to typing documents of any sort.
Many think of it as souped-up markdown, but this is a disservice to its utility.
It's so powerful, I could probably find a way to make it do my laundry[fn:1].

What initially drove me to org-mode was the function =org-latex-preview=.
In contrast to vim, emacs is a graphical program, which allows the program to /display images of compiled LaTeX over the text buffer you're editing./
Let's see what that looks like.

Org-mode is plaintext, so the raw text file you're editing might look something like this.

#+begin_example
**Hermitian Metrics
We'd like an analogue of Riemannian manifolds but "complexified".
Recall that a metric \( g \) is a \( 2\times 2 \) symmetric matrix at a point.
The complex analogue of "symmetric" is Hermitian, which motivates the following definition:

*Definition:* A /Hermitian metric/ on a complex manifold with local coordinates \( (z^1,\ldots , z^m) \) is a tensor field
\begin{equation*}
h_{j \overline{k}} dz^j\otimes dz^{\overline{k}}
\end{equation*}
where \( h_{j \overline{k}} \) varies smoothly, and is positive definite and Hermitian at each point \( z \).
The form
\begin{equation*}
\omega = \frac{i}{2} h_{j \overline{k}} dz^j\wedge dz^{\overline{k}}
\end{equation*}
is called the /Kahler form/ of the metric.
A complex manifold with a Hermitian metric is called a /Hermitian manifold/.
#+end_example

Here is this same snippet of text, but viewed in emacs, with all the org goodies activated.
[[~/Pictures/website/org-latex-goodies-ex.png]]

Notice how the compiled LaTeX appears inline, and the font size is variable for the heading.
These inline LaTeX previews are what pulled me to org-mode, and with the help of some third party programs like =xenops-mode=[fn:2], these previews render asynchronously as I continue typing.

There are many moving parts to this puzzle, but videos speak louder than words, so here is a quick demo.
#+caption: Sped up 30%
[[~/Videos/emacs-math-demo.gif]]

I could write more about how I achieved this setup, but others that are much smarter than me already have.


[fn:1] My [[*My DOOM Emacs Configuration][DOOM Emacs Config]] is typed in org-mode thanks to its literate programming abilities. In fact, this entire website is just one big org-mode file.

[fn:2] With org version 9.7, =xenops-mode= will be wholly unnecessary thanks to a new default =org-latex-preview= function. See a demo [[https://www.youtube.com/watch?v=n-AfvuV-bYo&t=376s][here]].

** My DOOM Emacs Configuration :emacs:org:hobby:
:PROPERTIES:
:EXPORT_HUGO_SECTION: computing
:EXPORT_FILE_NAME: doom-config
:END:
#+attr_html: :class toc-class
#+begin_details
#+begin_summary
*Table of Contents*
#+end_summary
#+toc: headlines 2 local
#+end_details
#+include: ~/.doom.d/config.org
** Declarative Programming for UltraFast™ Brain-to-Binary
:PROPERTIES:
:EXPORT_HUGO_SECTION: computing
:EXPORT_FILE_NAME: brain_to_binary_bliss_of_decla_prog
:END:
Recently I've been messing around with different programming languages and branching out beyond the C-style languages I know like C++ and Python.
In my search for one to try out, I discovered Haskell, and the paradigm of functional programming as a whole.

As a mathematician by trade, the usefulness of programming was never lost on me.
From my time with C++ and Python, I had developed a (not unreasonable) notion that programming was all about telling computers how to do something you want done..
This changed when I learned of the functional programming paradigm, or more generally, declarative-style languages.

Suppose we wanted to write a function =fun= that takes in a non-negative integer and returns the sum of squares of numbers between 0 and that integer.
In fancy math language, the function would look like this:
\begin{align*}
\mathtt{fun} : \mathbf{Z}_{ \geqslant 0} &\to \mathbf{Z}_{\geqslant 0} \\
                                \mathtt{fun}(k)       &= \sum_{i=1}^k i^2.
\end{align*}

Let's implement this in Python with an imperative style of writing:
#+begin_src python
def fun(k):
    num = 0
    for i in range(k + 1):
        num += i**2
    return i
#+end_src
We're telling the computer here to step through all non-negative integers up to =k= and adding the square of these integers to a cumulative sum of all the previous numbers.
Perfectly intuitive and reasonable.

Let's implement this in Haskell, a more-or-less pure functional programming language with a highly expressive, declarative style of syntax:
#+begin_src haskell
fun k = sum [i*i | i <- [0..k]]
#+end_src
This solution is elegant once you know that the =<-= syntax is the set containment symbol \( \in \) from mathematics.

This declarative style of writing code is something I find myself coming back to whenever I want to quickly hack an idea together.
It lets me focus on implementing the key steps of the problem I have laid out, without getting bogged down with more minor details of how it should be solved.
Focusing on the /what/ and not the /how/ is a fast-track to getting a compiled program that does what you want it to do quickly.

Of course, this type of programming is not without faults.
For one, you are leaving the "how" up to compiler with how it implements the expressive syntax.
Compiler engineers and developers for the languages are a clever bunch, but if you want more fine-grain control, the imperative style is superior.

Another drawback to the declarative style is working on large projects with many developers.
Since declarative programs tend to read closer to natural language, it's possible that each developer will craft their own dialect within the confines of the syntax.
Having several people with several dialects working on a single project can be a challenge.
Oftentimes for the sake of team cohesion and ease of debugging, a unified style-guide for large projects is preferred.

Despite this, I will continue to prefer declarative programming for quick implementations, only moving to imperative when I think more control is needed.
* Misc
:PROPERTIES:
:EXPORT_HUGO_SECTION: misc
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :type post
:END:
** Misc
:PROPERTIES:
:EXPORT_HUGO_SECTION: misc
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_MENU: :menu main
:END:
Some stuff that doesn't really fit anywhere else.
** Astrophotos :astro:hobby:
:PROPERTIES:
:EXPORT_HUGO_SECTION: misc
:EXPORT_FILE_NAME: astrophotos
:END:
As a fairly new astrophotographer, these images will be quite poor to the discerning eye. Artifacts like dust spots, field curvature, and star trails can be seen in pretty much all of them, among many more artifacts. Regardless, I find a lot of satisfaction in this hobby as a fascinating blend of science and art.
*** M101: Pinwheel Galaxy
#+name: m101
#+caption: M101, The Pinwheel Galaxy
[[file:~/Pictures/astro/m101_take2.jpg][file:~/Pictures/astro/m101_take2.jpg]]
#+begin_details
#+begin_summary
Details
#+end_summary

It's been a while since I took this image, but I belive it total around 3 hours of integration
#+end_details
*** M42: The Orion Nebula
#+name: m42
#+caption: M42, The Orion Nebula
[[file:~/Pictures/astro/orion_phone_wallpaper.jpg][file:~/Pictures/astro/orion_phone_wallpaper.jpg]]
#+begin_details
#+begin_summary
Details
#+end_summary
This image was processed from my first ever outing doing astrophotography. It totals around 12 minutes of integration from the Bortle 1 sky around the McDonald Observatory. Weather prevented any more data collection, but I'm still surprised at how much I was able to get out of it. By contrast my [[*M101: Pinwheel Galaxy][image of M101]] was taken from a very light-polluted Bortle 8 sky, and that image was 3 hours of integration. This image always surprises me at how much better it is to image under dark skies.

The uneven illumination on the bottom left of the image is due to a strange reflection pattern on an IR cut filter I have for my camera. It's not present in other images because I imaged those without the filter.
#+end_details
** Some Theorems
:PROPERTIES:
:EXPORT_HUGO_SECTION: misc
:EXPORT_FILE_NAME: fav_theorems
:END:

#+begin_details
#+begin_summary
Table of Contents
#+end_summary
#+toc: headlines 1
#+end_details

*** Modular categories are not determined by their modular data
#+begin_details
#+begin_summary
A modular category \( \mathcal{C} \) is not determined by its \( S \) and \( T \) matrices.
#+end_summary

*Comments:* If something seems too good to be true, it probably is.
#+end_details
*** Classification of commutative Frobenius algebras by TQFTs
#+begin_details
#+begin_summary
For a field \( k \), there is an equivalence of categories \( \mathsf{2TQFT}_k \simeq \mathsf{cFrob}_k \) of 2-dimensional topological quantum field theories and commutative Frobenius algebras.
#+end_summary

*Comments:* This was the first result I learned that expressed how some classical tensor algebras arise as categorical constructions. Essential to this equivalence is the classification of closed 1-dimensional manifolds and how well behaved the category \( \mathsf{2Cob} \) is. A significant amount of work is needed to even hypothesize a higher dimensional analogue. This is the cobordism hypothesis, proposed by Baez and Dolan.
#+end_details
*** The Yoneda Lemma
#+begin_details
#+begin_summary
Let \( \mathsf{C} \) be a locally small category and \( F : \mathsf{C} \to \mathsf{Set} \) be a functor. Then
\[
\operatorname*{Hom}(\operatorname*{Hom}(X,-),F) \cong FX
\]
and this isomorphism is natural in both \(X\) and \(F\).
#+end_summary

*Comments:* This theorem is remarkable. The object on the left, as a collection of natural transformations, is seemingly incalculably large. Not only does this theorem tell us that this collection is a set, but it also gives an *explicit description* of these transformations, parameterized by \( FX \). When applied to \( F = \operatorname*{Hom}(Y,-) \) (or more generally representable functors), this theorem gives meaning to the intuitively-known idea that an object is uniquely determined by the maps into (our out of) it.
#+end_details
* 日本語コーナー
:PROPERTIES:
:EXPORT_HUGO_SECTION: nihongo
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :type post
:END:
** 日本語コーナー
:PROPERTIES:
:EXPORT_HUGO_SECTION: nihongo
:EXPORT_HUGO_MENU: :menu main
:EXPORT_FILE_NAME: _index
:END:

ここで日本語に関して勉強したり読んだりするものを話す。

** 「氷が効かなくなってきている」
:PROPERTIES:
:EXPORT_HUGO_SECTION: nihongo
:EXPORT_FILE_NAME: jojos_interesting_phrase
:END:
I came across the phrase「氷が行かなくなってきている」in an episode of Jojo's Bizarre Adventure and couldn't help but smile at it.
The morphology of Japanese words is a fascinating one, and this sentence exemplifies it brilliantly.
Roughly, this sentence says "the ice is becoming ineffective", or more naturally, "the ice is becoming less effective".
The first word 「氷」, is straightforward; it means "ice".
The particle 「が」 is an indicative particle meant to direct the attention of the listener to the noun it is attached to.

Now here comes the interesting part: the final 「効かなくなってきている」.
The base of this phrase is 「効く」, which means "to be effective, to function, to work".
From here, the verb is morphed to its negative 「効かない」.
Of course, this means "to not be effective".
One cool things about Japanese is that most words that end in 「い」morph like 「ーい」adjectives.
One such way 「ーい」adjective morph is by replacing the い with く.
This morph is typically described as turning the adjective into an adverb, but the idea of turning a negative-conjugated verb into an adverb is a bit mysterious, especially since no such pattern exists in english.
Now we're left with 「効かなく」.

Now that we have an "adverb", we need a verb for it to describe.
This is where 「なる」comes in.
The entire last part 「なってきている」is a morph of this verb, which means "to become".
「なる」 becomes 「なって」, which is a special morph (called -te form) of verbs that can set up a number of new morphs.
From here we add the verb 「来る」, which means "to come to be".
From 「なって来る」 we then turn the 「来る」 into /its/ -te form, yielding 「なってきて」.
(It's worth nothing that this construction is usually written in kana, hence I drop the kanji.)
The final addition is the verb 「いる」.
When this verb is added to the -te form of another verb, it expresses an enduring state of action.
Oftentimes this translated to the present progressive form in english, e.g. run -> /running/.

So we're left with 「なってきている」, which roughly means "is becoming".
The nuance of the 「きて」 is sadly lost since there is no real way to directly translate this to english.

When I first heard this sentence it took me some seconds to parse.
As an english native speaker, I'm not used to having to listen this long to a single phrase to glean its meaning.
Let's take a different approach to illustrate how long words can be constructed.

Remember the 「ーい」 adjective morphs I mentioned?
It turns out that the negative of an 「ーい」 adjective is also an 「ーい」 adjective!
As such, there is theoretically *no upper bound to how long of a "word" you can grammatically correctly construct in Japanese*.

The construction is simple: take an 「ーい」 adjective and negate it.
The way to do this is change the final 「い」 to 「くない」.
Repeat.
For example with the word 「よい」, meaning "good", we can negate it twice to the word meaning "not not good":
#+begin_example
よい ー> よくない ー> よくなくない
#+end_example
But the final word here is also an 「ーい」 adjective.
This means that this is also a grammatically correct construction:
#+begin_example
よくなくなくなくなくなくなくなくなくなくなくなくなくない
#+end_example
Repeat as needed to construct as long of a word as you want.
Of course, we've long left the issue of pragmatism behind, but still, it's pretty not not not not not not not not not not not not not not not not cool, huh?

* Drafts and Ideas
